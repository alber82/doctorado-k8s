## Default values.yaml for Telegraf
## This is a YAML-formatted file.
## ref: https://hub.docker.com/r/library/telegraf/tags/

replicaCount: 1
image:
  repo: "docker.io/library/telegraf"
  tag: "1.32.1-alpine"
  pullPolicy: IfNotPresent
podAnnotations: {}
podLabels: {}
imagePullSecrets: []
## Configure args passed to Telegraf containers
args: []
# The name of a secret in the same kubernetes namespace which contains values to
# be added to the environment (must be manually created)
# This can be useful for auth tokens, etc.

# envFromSecret: "telegraf-tokens"
env:
  - name: HOSTNAME
    value: "telegraf-polling-service"
# An older "volumeMounts" key was previously added which will likely
# NOT WORK as you expect. Please use this newer configuration.

volumes:
  - name: telegraf-ca
    secret:
      secretName: telegraf-ca

mountPoints:
  - name: telegraf-ca
    mountPath: /etc/telegraf/ca
    readOnly: true      

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources: {}
requests:
  memory: 64Mi
  cpu: 50m
limits:
  memory: 128Mi
  cpu: 100m

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
nodeSelector: {}
## Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - worker04

## Tolerations for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []
# - key: "key"
#   operator: "Equal|Exists"
#   value: "value"
#   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

## Configure the updateStrategy used to replace Telegraf Pods
## See https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
updateStrategy: {}
#  type: RollingUpdate|Recreate
#  rollingUpdate:
#    maxUnavailable: 1
#    maxSurge: 1

service:
  enabled: false
rbac:
  # Specifies whether RBAC resources should be created
  create: true
  # Create only for the release namespace or cluster wide (Role vs ClusterRole)
  clusterWide: false
  # Rules for the created rule
  rules: []
# When using the prometheus input to scrape all pods you need extra rules set to the ClusterRole to be
# able to scan the pods for scraping labels. The following rules have been taken from:
# https://github.com/helm/charts/blob/master/stable/prometheus/templates/server-clusterrole.yaml#L8-L46
#    - apiGroups:
#        - ""
#      resources:
#        - nodes
#        - nodes/proxy
#        - nodes/metrics
#        - services
#        - endpoints
#        - pods
#        - ingresses
#        - configmaps
#      verbs:
#        - get
#        - list
#        - watch
#    - apiGroups:
#        - "extensions"
#      resources:
#        - ingresses/status
#        - ingresses
#      verbs:
#        - get
#        - list
#        - watch
#    - nonResourceURLs:
#        - "/metrics"
#      verbs:
#        - get

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: telegraf
  # Annotations for the ServiceAccount
  annotations: {}
## Exposed telegraf configuration
## For full list of possible values see `/docs/all-config-values.yaml` and `/docs/all-config-values.toml`
## ref: https://docs.influxdata.com/telegraf/v1.1/administration/configuration/
config:
  agent:
    interval: "15s"
    round_interval: true
    metric_batch_size: 10000
    metric_buffer_limit: 200000
    collection_jitter: "0s"
    flush_interval: "15s"
    flush_jitter: "0s"
    precision: ""
    debug: true
    quiet: false
    logfile: ""
    hostname: "$HOSTNAME"
    omit_hostname: false

  processors:
    - enum:
        mapping:
          field: "status"
          dest: "status_code"
          value_mappings:
            healthy: 1
            problem: 2
            critical: 3
    - starlark:
        namepass: ["node_cpu_seconds_total"]
        source: |
          state = {}

          def apply(metric):
              if metric.name != "node_cpu_seconds_total":
                  return metric

              # Extraer IP desde la URL
              url = metric.tags.get("url", "")
              if not url:
                  return metric

              parts = url.split("://")
              if len(parts) > 1:
                  ip_port = parts[1].split("/")[0]
                  ip = ip_port.split(":")[0]
              else:
                  ip = "unknown"

              cpu = metric.tags.get("cpu", "0")
              mode = metric.tags.get("mode", "")
              key = ip + "_" + cpu + "_" + mode
              now = float(metric.time)
              value = float(metric.fields.get("counter", 0))

              if not key in state:
                  state[key] = {"value": value, "time": now}
                  return metric

              prev = state[key]
              delta_value = value - prev["value"]
              delta_time = (now - prev["time"]) / 1e9  # en segundos

              if delta_time <= 0 or delta_value < 0:
                  return metric

              usage_frac = 0.0
              if mode != "idle":
                  usage_frac = delta_value / delta_time

              # Guardar nuevo estado
              state[key] = {"value": value, "time": now}

              # Acumular por IP
              agg_key = ip + "_sum"
              if not agg_key in state:
                  state[agg_key] = {"sum": 0.0, "count": 0}

              state[agg_key]["sum"] += usage_frac
              state[agg_key]["count"] += 1

              # Solo cuando cpu=="0", emitir métrica final
              if cpu != "0":
                  return metric

              total = state[agg_key]
              avg_usage = total["sum"] / total["count"] if total["count"] > 0 else 0.0
              state[agg_key] = {"sum": 0.0, "count": 0}  # reset

              # Estimación según tipo de RPi
              if ip in ["192.168.1.220", "192.168.1.221", "192.168.1.222", "192.168.1.223"]:
                  idle_w = 4.5
                  load_w = 10.0
                  modelo = "rpi5"
              elif ip in ["192.168.1.224", "192.168.1.225"]:
                  idle_w = 3.4
                  load_w = 6.4
                  modelo = "rpi4"
              else:
                  idle_w = 3.5
                  load_w = 7.0
                  modelo = "unknown"

              power = idle_w + avg_usage * (load_w - idle_w)
              power = float(int(power * 10)) / 10.0  # redondeo a 1 decimal

              new_metric = Metric("rpi_power_watts")
              new_metric.fields["value"] = power
              new_metric.tags["ip"] = ip
              new_metric.tags["modelo"] = modelo
              new_metric.time = metric.time

              return [metric, new_metric]

#         namepass: ["node_cpu_seconds_total"]
#         source: |
#           state = {}
#
#           def avg(vals):
#               total = 0.0
#               count = 0
#               for v in vals:
#                   total += v
#                   count += 1
#               if count == 0:
#                   return 0.0
#               return total / count
#
#           def apply(metric):
#               if metric.tags.get("mode") != "idle":
#                   return metric
#
#               url = metric.tags.get("url", "")
#               if "://" in url:
#                   url = url.split("://")[1]
#               ip = url.split(":")[0] if ":" in url else url
#               metric.tags["ip"] = ip
#
#               cpu = metric.tags.get("cpu", "all")
#               key = ip + "_" + cpu
#               now = float(metric.time)
#               idle_now = float(metric.fields.get("counter", 0))
#
#               prev = state.get(key)
#               if not prev:
#                   state[key] = {"idle": idle_now, "time": now}
#                   return metric
#
#               idle_delta = idle_now - prev["idle"]
#               time_delta = (now - prev["time"]) / 1e9
#
#               if idle_delta < 0 or time_delta <= 0:
#                   return metric
#
#               usage = 1.0 - (idle_delta / time_delta)
#
#               state[key] = {"idle": idle_now, "time": now}
#
#               if not ip in state:
#                   state[ip] = []
#               state[ip].append(usage)
#
#               if cpu != "0":
#                   return metric
#
#               usage_vals = state[ip]
#               avg_usage = avg(usage_vals)
#               state[ip] = []
#
#               if ip in ["192.168.1.220", "192.168.1.221", "192.168.1.222", "192.168.1.223"]:
#                   modelo = "rpi5"
#                   idle_w = 4.5
#                   load_w = 10.0
#               elif ip in ["192.168.1.224", "192.168.1.225"]:
#                   modelo = "rpi4"
#                   idle_w = 3.4
#                   load_w = 6.4
#               else:
#                   modelo = "unknown"
#                   idle_w = 3.5
#                   load_w = 7.0
#
#               power = idle_w + avg_usage * (load_w - idle_w)
#               m = Metric("rpi_power_watts")
#               m.fields["value"] = power
#               m.tags["ip"] = ip
#               m.tags["modelo"] = modelo
#               m.time = metric.time
#
#               return [metric, m]

  outputs:
    - influxdb_v2:
        urls: ["http://influxdb-influxdb2:80"]
        token: "klsjdaioqwehrqoikdnmxcq"
        organization: "uclm"
        bucket: "doctorado"
        namepass:
        - node_cpu_seconds_total
        - node_disk_reads_completed_total
        - node_disk_writes_completed_total
        - node_disk_read_bytes_total
        - node_disk_written_bytes_total
        - node_filesystem_size_bytes
        - node_filesystem_free_bytes
        - node_filesystem_avail_bytes
        - node_filesystem_files
        - node_network_receive_bytes_total
        - node_network_transmit_bytes_total
        - node_network_receive_packets_total
        - node_network_transmit_packets_total
        - rpi_power_watts
  inputs:
    - prometheus:
        tls_ca: "/etc/telegraf/ca/ca.crt"
        insecure_skip_verify: true
        urls:
          - https://192.168.1.220:9100/metrics
          - https://192.168.1.221:9100/metrics
          - https://192.168.1.222:9100/metrics
          - https://192.168.1.223:9100/metrics
          - https://192.168.1.224:9100/metrics
          - https://192.168.1.225:9100/metrics
metrics:
  health:
    enabled: false
    service_address: "http://:8888"
    threshold: 5000.0
  internal:
    enabled: true
    collect_memstats: false
# Lifecycle hooks
# hooks:
#   postStart: ["/bin/sh", "-c", "echo Telegraf started"]
#   preStop: ["/bin/sh", "-c", "sleep 60"]

## Pod disruption budget configuration
##
pdb:
  ## Specifies whether a Pod disruption budget should be created
  ##
  create: false
  minAvailable: 1
  # maxUnavailable: 1

# containerPorts:
# - name: http
#   containerPort: 9273
#   protocol: TCP

